{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Profner.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9f2a1866d4f44ec8b32535304bc59d43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0bc86e394e804b168650f123a34e0939",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6bab9d72ba3141e3a8dd004d2a16a64b",
              "IPY_MODEL_c7cea3642cb3483fa6293ae37885411f"
            ]
          }
        },
        "0bc86e394e804b168650f123a34e0939": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6bab9d72ba3141e3a8dd004d2a16a64b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f4eeb85835ae45748cd2d8684c5a600f",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 871891,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 871891,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ce4d9ca911314fd78a08ddd896eaefb0"
          }
        },
        "c7cea3642cb3483fa6293ae37885411f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3d0c4aa865364f7193ce8b4dc3598d76",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 872k/872k [00:00&lt;00:00, 1.86MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6c767374a8b24a669e18fd76ce9b0378"
          }
        },
        "f4eeb85835ae45748cd2d8684c5a600f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ce4d9ca911314fd78a08ddd896eaefb0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3d0c4aa865364f7193ce8b4dc3598d76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6c767374a8b24a669e18fd76ce9b0378": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/francesita/ProfnerTask7a/blob/main/Copy_of_Profner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7L_oT3q2rdq"
      },
      "source": [
        "#Code Profner Task 7a: Binary classification: Identifying occupations in social media text\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2lk86045Xes",
        "outputId": "b58c6af4-4f7b-43d2-b653-a0c4cd32c66c"
      },
      "source": [
        "#mount googleDrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EH5rh8O62NIy"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dl6mTbo_CKnh"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import Accuracy, Recall\n",
        "import tensorflow.keras.backend as K"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfntiEYPCqRf"
      },
      "source": [
        "##Preprocess tweets \n",
        "\n",
        "1. remove twitter handles, links, hashtags, punctuation etc. so that we are left solely with text in the tweet\n",
        "2. tokenize tweets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pgFVGA4DOcg"
      },
      "source": [
        "import re\n",
        "\n",
        "def preprocess_tweets(tweet):\n",
        "  \"\"\"\n",
        "  - remove hashtags, twitter handles, url's\n",
        "  \"\"\"\n",
        "  #might want to try replacing @mentions with a word, such as person/persona?\n",
        "  #tweet = re.findall(r'#(\\w+)', tweet, re.UNICODE)\n",
        "  tweet = ' '.join(re.sub(r\"(@[A-Za-z0-9_]+)|([Ã¡Ã©Ã­Ã³ÃºÃ±Ã¼][^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\",\" \",tweet).split())\n",
        "  tweet = tweet.replace(\"#\", \"\").replace(\"_\", \" \")\n",
        "  #remove emojis from tweets\n",
        "  #tweet = remove_emoji(tweet)\n",
        "  return tweet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3K49D2Kb541_"
      },
      "source": [
        "import string\n",
        "def remove_punctuation(tknzd_tweet):\n",
        "  spanish_pnct = (['Â¿','Â¡',':','Â¨','...',\"'\",'â‚¬','Â£','$','\"','@'])\n",
        "  cln_twt = []\n",
        "  for token in tknzd_tweet:\n",
        "    if token not in string.punctuation and token not in spanish_pnct:\n",
        "      cln_twt.append(token)\n",
        "  \n",
        "  return cln_twt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXgZ2qEJ-uF7"
      },
      "source": [
        "!pip install demoji\n",
        "import demoji\n",
        "demoji.download_codes()\n",
        "#remove emojis from tweet\n",
        "def remove_emoji(tweet):\n",
        "  tweet = demoji.replace(tweet, \"\")\n",
        "\n",
        "  return tweet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3YNb-F9WbN1"
      },
      "source": [
        "We check that the tweets are preprocessed as expected by use of an example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5P-BZv3rdq1B",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "5f26cfb5-5a0f-4945-f227-531fc5af2c49"
      },
      "source": [
        "text = 'CuÃ±ado, vÃ©n conmigo maÃ±ana para comer arroz. Â¡TÃº eres tÃ¡n estÃºpida! @lal_oca #ror_dfa ðŸ˜œðŸ‡µðŸ‡·ðŸ’€â›µðŸˆµðŸ‡¸ðŸ‡» @'\n",
        "preprocess_tweets(text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'CuÃ±ado, vÃ©n conmigo maÃ±ana para comer arroz. Â¡TÃº eres tÃ¡n estÃºpida! ror dfa ðŸ˜œðŸ‡µðŸ‡·ðŸ’€â›µðŸˆµðŸ‡¸ðŸ‡» @'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgMOgtqu2_b7"
      },
      "source": [
        "##Preprocess tweet for pretrained mBERT and BERT\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Jlj3XDS9GO0"
      },
      "source": [
        "#defining function to preprocess with Bert\n",
        "def preprocess_bert(tweets, pt_tokenizer_model, max_len):\n",
        "    '''\n",
        "    This function will do a variety of things to prep data for Roberta (through encode_plus) which includes:\n",
        "      -tokenizing tweet\n",
        "      -adding <s> BOS token (used for classification) and </s></s> as a [SEP] token to start and end of tweet\n",
        "      -pad or truncate the tweet to max length\n",
        "      -map tokens to their encoding or id\n",
        "      -creates attention mask: this is a mask used for attention when a batch has varying length of sentences\n",
        "      -returns a dict of outputs\n",
        "      -all this comes from fine-tuning tutorial from skimai.com\n",
        "    '''\n",
        "\n",
        "    tokenizer = BertTokenizer.from_pretrained(pt_tokenizer_model, do_lower_case = True)\n",
        "\n",
        "    encoded_tweets = []\n",
        "    #attention masks indicated to the model we will use, which tokens should be attended to, example indicates position of padding\n",
        "    #so model should not pay attention to these. \n",
        "    attention_masks = []\n",
        "\n",
        "\n",
        "    for tweet in tweets:\n",
        "        encoded_tweet = tokenizer.encode_plus(\n",
        "            text = preprocess_tweets(tweet),\n",
        "            add_special_tokens=True, #cls and sep tokens \n",
        "            max_length=max_len,\n",
        "            pad_to_max_length=True,\n",
        "            return_attention_mask=True)\n",
        "\n",
        "        #add outputs to list\n",
        "        encoded_tweets.append(encoded_tweet.get('input_ids'))\n",
        "        attention_masks.append(encoded_tweet.get('attention_mask'))\n",
        "      \n",
        "    #we now convert the lists to tensors\n",
        "    encoded_tweets = np.asarray(encoded_tweets, dtype='int32')\n",
        "    attention_masks = np.asarray(attention_masks, dtype='int32')\n",
        "\n",
        "    return encoded_tweets, attention_masks\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pmm2memefp7L"
      },
      "source": [
        "#Model using mBert Sequence Classifier\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPRsqx0zyzbL"
      },
      "source": [
        "Load data for the model. The data needs to be encoded differently from the BiLSTM classifier above. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRR4nRiFyC4m"
      },
      "source": [
        "#import data\n",
        "train_data = pd.read_csv('/content/drive/MyDrive/Datasets/profner/train.csv')\n",
        "val_data = pd.read_csv('/content/drive/MyDrive/Datasets/profner/val.csv')\n",
        "aug_data = pd.read_csv('/content/drive/MyDrive/Datasets/profner/train-aug-trans.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "x9qFieFzqW8Y",
        "outputId": "6de50bf6-4fa6-406c-8a6a-b52a53e851d3"
      },
      "source": [
        "train_data.loc[train_data['label'] == 1].head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1252741192577581056</td>\n",
              "      <td>['Repartidores teniendo que trabajar en medio ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1260266403409670144</td>\n",
              "      <td>['@carlesenric @salvadorilla Es imprescindible...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1256473507157999616</td>\n",
              "      <td>['El mismo esfuerzo que heces tu , que ni  te ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>1251254299029618690</td>\n",
              "      <td>['Contexto:\\n', '\\n', '- ComisarÃ­a con cajas d...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>1260647157549264896</td>\n",
              "      <td>['Que la directora del Centro Nacional de Epid...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Unnamed: 0  ... label\n",
              "8   1252741192577581056  ...     1\n",
              "9   1260266403409670144  ...     1\n",
              "17  1256473507157999616  ...     1\n",
              "18  1251254299029618690  ...     1\n",
              "19  1260647157549264896  ...     1\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "d3VBEXeYkycs",
        "outputId": "7a22d298-c51e-4ee2-d8bb-79bc092238f0"
      },
      "source": [
        "aug_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8</td>\n",
              "      <td>1252741192577581056</td>\n",
              "      <td>[\"Los repartidores tienen que trabajar en medi...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9</td>\n",
              "      <td>1260266403409670144</td>\n",
              "      <td>['@carlesenric @salvadorilla Es imprescindible...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>17</td>\n",
              "      <td>1256473507157999616</td>\n",
              "      <td>['El mismo esfuerzo que haces, ni siquiera abr...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>18</td>\n",
              "      <td>1251254299029618690</td>\n",
              "      <td>['Contexto: \\ n', '\\ n', '- ComisarÃ­a de polic...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>19</td>\n",
              "      <td>1260647157549264896</td>\n",
              "      <td>['Que el director del Centro Nacional de Epide...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...  label\n",
              "0           8  ...      1\n",
              "1           9  ...      1\n",
              "2          17  ...      1\n",
              "3          18  ...      1\n",
              "4          19  ...      1\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ja2xWGWFTPRV"
      },
      "source": [
        "es_train = list(train_data.tweet)\n",
        "aug_train = list(aug_data.tweet)\n",
        "val = val_data.tweet\n",
        "\n",
        "es_labels = list(train_data.label)\n",
        "aug_labels = list(aug_data.label) \n",
        "val_labels = val_data.label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fB7tMji1NOP"
      },
      "source": [
        "#turn train data lists to numpy arrays\n",
        "train = np.asarray(es_train)\n",
        "aug_train = np.asarray(aug_train)\n",
        "\n",
        "labels = np.asarray(es_labels)\n",
        "aug_labels= np.asarray(aug_labels)\n",
        "\n",
        "#Combine training data\n",
        "train = np.append(es_train, aug_train)\n",
        "labels = np.append(es_labels, aug_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VcqvuxdKL41t",
        "outputId": "de817eb0-8b6a-4ba2-8a5e-81beab7951e5"
      },
      "source": [
        "print('Number of tweets augmented are: ', len(aug_train))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of tweets augmented are:  1393\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIdsjnaE07wj"
      },
      "source": [
        "#shuffle data for both train and val sets\n",
        "idx = np.random.permutation(len(train))\n",
        "x_train, y_train = train[idx],labels[idx]\n",
        "\n",
        "x_val, y_val = val,val_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04IW9EXYNxv9",
        "outputId": "5b27e64d-5027-4f0a-fe77-e59d5320f7ce"
      },
      "source": [
        "print('Total number of training examples after agumemnted data is addeds is: ' , len(x_train))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of training examples after agumemnted data is addeds is:  7393\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyJBr70W8Qcb"
      },
      "source": [
        "!pip install transformers\n",
        "from transformers import BertTokenizer, TFBertForSequenceClassification"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "847cQR4ZpUUY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "9f2a1866d4f44ec8b32535304bc59d43",
            "0bc86e394e804b168650f123a34e0939",
            "6bab9d72ba3141e3a8dd004d2a16a64b",
            "c7cea3642cb3483fa6293ae37885411f",
            "f4eeb85835ae45748cd2d8684c5a600f",
            "ce4d9ca911314fd78a08ddd896eaefb0",
            "3d0c4aa865364f7193ce8b4dc3598d76",
            "6c767374a8b24a669e18fd76ce9b0378"
          ]
        },
        "outputId": "a992d0d0-c72c-4118-802d-7c48f7df4774"
      },
      "source": [
        "#load mBERT tokenizer, we will use it later in a function (this one is used to encode to find max_len)\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-uncased', do_lower_case = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9f2a1866d4f44ec8b32535304bc59d43",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=871891.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMGi08AeBWAo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ff75a26-5d18-4662-8d63-cbf385b64f91"
      },
      "source": [
        "#Now we find maximum length in our list of tweets with the special tokens\n",
        "\n",
        "#we concatenate training and validation sets \n",
        "all_tweets = np.concatenate([train_data.tweet, val_data.tweet])\n",
        "\n",
        "#encode using tokenizer function (not our fucntion with encoded_plus, this is because we want to see max_length of tweet with special tokens)\n",
        "all_tweets_encoded = [tokenizer.encode(tweet, add_special_tokens=True) for tweet in all_tweets]\n",
        "print(all_tweets_encoded[0])\n",
        "print(tokenizer.decode(all_tweets_encoded[0]))\n",
        "\n",
        "#find maximum length\n",
        "max_len = max([len(tweet) for tweet in all_tweets_encoded])\n",
        "print('max length of tweets:', max_len)\n",
        "\n",
        "#find avg length\n",
        "# we might want to use avg len rather than max length in future\n",
        "avg_len = int(np.average([len(tweet) for tweet in all_tweets_encoded]))\n",
        "print('average len:' ,avg_len)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[101, 138, 112, 11707, 131, 35366, 10155, 14618, 22754, 10278, 139, 156, 112, 117, 112, 23329, 119, 31270, 131, 35366, 34742, 12905, 139, 156, 112, 117, 112, 12761, 131, 35366, 78509, 139, 156, 112, 117, 112, 10209, 10295, 10295, 10295, 10295, 10295, 10295, 112, 140, 102]\n",
            "[CLS] ['china : libera una pandemia \\ n ','ee. uu : libera ovnis \\ n ','argentina : libera presos \\ n ','jajajajajajaja'] [SEP]\n",
            "max length of tweets: 343\n",
            "average len: 69\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHM3_wjCbf4O"
      },
      "source": [
        "#define var with model type\n",
        "m_tokenizer = 'bert-base-multilingual-uncased'\n",
        "max_len = 80\n",
        "#tokenize our tweets using the pre-proprocess function we defined earlier\n",
        "train_inputs, train_masks = preprocess_bert(x_train, m_tokenizer, max_len)\n",
        "val_inputs, val_masks = preprocess_bert(x_val, m_tokenizer, max_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kl8GXzLr9Lye",
        "outputId": "f0bcb4ae-7f8e-47bb-ba12-f5ab12945f43"
      },
      "source": [
        "print(train_inputs[0])\n",
        "print(train_masks[0])\n",
        "print(y_train[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[  101   138   112 10265 16422 10107 10128 23145 41881 11823 10119 12715\n",
            "   110 10109 10117 29346 10102 10106 84315 10102 20241 70294   117 10173\n",
            " 11589   119 10292 46720 38183 10321 10109 10426 17530 11310 10190   112\n",
            "   140   102     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0]\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XikBiAni8qX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73dbb212-d611-4db2-e40a-98599db62f31"
      },
      "source": [
        "print('shape of train_inputs:', train_inputs.shape)\n",
        "print('shape of train_masks', train_masks.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shape of train_inputs: (7393, 80)\n",
            "shape of train_masks (7393, 80)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxC9Sgy1zrMH"
      },
      "source": [
        "##Fine-tune mBERT and mBERT-Aug classification model\n",
        "\n",
        "The following function is used to create both the mBERT model and the mBERT-Aug model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALYx2cOh-dUD"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "#making labels into numpy arrays for training in transformers and keras\n",
        "def create_transformer_model(pre_trained_model, num_labels, max_len):\n",
        "  transformer_model = TFBertForSequenceClassification.from_pretrained(pre_trained_model, num_labels=num_labels)\n",
        "\n",
        "  #We create keras tensors\n",
        "  input_ids = tf.keras.layers.Input(shape=(max_len,), name='train_input', dtype=tf.int32)\n",
        "  input_masks = tf.keras.layers.Input(shape=(max_len), name='train_masks', dtype=tf.int32)\n",
        "\n",
        "  #take into account single dimension\n",
        "  seq_outputs = transformer_model(input_ids, input_masks)[0]\n",
        "  outputs = tf.keras.layers.Dense(num_labels, activation='sigmoid')(seq_outputs)\n",
        "\n",
        "  model = tf.keras.models.Model(inputs=[input_ids,input_masks], outputs=outputs)\n",
        "\n",
        "  print(model.summary())\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2klMngltfWuI",
        "outputId": "1b635647-ddca-4609-d397-8f7078c20680"
      },
      "source": [
        "pt_trans_model = 'bert-base-multilingual-uncased'\n",
        "num_labels = 1\n",
        "loss = 'binary_crossentropy'\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)  #learning-rate is changed depending on the model we wish to train\n",
        "\n",
        "\n",
        "model = create_transformer_model(pt_trans_model, num_labels, 80)\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7fca70106c20> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function wrap at 0x7fca70106c20> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convertWARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "train_input (InputLayer)        [(None, 80)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "train_masks (InputLayer)        [(None, 80)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_bert_for_sequence_classifica TFSequenceClassifier 167357185   train_input[0][0]                \n",
            "                                                                 train_masks[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 1)            2           tf_bert_for_sequence_classificati\n",
            "==================================================================================================\n",
            "Total params: 167,357,187\n",
            "Trainable params: 167,357,187\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZ6j0jXZ1zTS"
      },
      "source": [
        "#make labels into numpy arrays, and prep x_val\n",
        "x_val = [val_inputs, val_masks]\n",
        "#turn labels into tensors\n",
        "y_train = np.asarray(y_train, dtype='int32')\n",
        "y_val = np.asarray(y_val, dtype='int32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-ULINSSjLw2"
      },
      "source": [
        "#fit model to input data\n",
        "\n",
        "with tf.device('/device:GPU:0'):\n",
        "  model.fit([train_inputs, train_masks], y_train, validation_data=(x_val, y_val), epochs=3, batch_size = 32)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAdUtrvy06su"
      },
      "source": [
        "#save model\n",
        "model.save_weights('filepath/filename')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FKYnynBEaSc"
      },
      "source": [
        "##Testing and Error Analysis on mBert Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flOryVfl1bjb"
      },
      "source": [
        "#load model if not already---> in this case we load the augmented data model\n",
        "model.load_weights('/content/drive/MyDrive/Colab/saved_model/mBert_profner_aug.hdf5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6zGa5XOG0uL"
      },
      "source": [
        "def assign_class(a_pred):\n",
        "  pred = []\n",
        "  for i in range(len(a_pred)):\n",
        "    if a_pred[i] >= 0.5:\n",
        "      pred.append(1)\n",
        "    else:\n",
        "      pred.append(0)\n",
        "  return pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDZwrJhDExqL"
      },
      "source": [
        "#make predictions on model\n",
        "y_pred = model.predict([val_inputs, val_masks])\n",
        "es_pred = assign_class(y_pred)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cw4WrEpNFATR"
      },
      "source": [
        "###Confusion Matrix for mBert Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNGvErUYFcQ7",
        "outputId": "1c7b2110-bd9d-45dc-b575-1908df6779fb"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, f1_score\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y_true = y_val\n",
        "y_pred = es_pred\n",
        "\n",
        "print(confusion_matrix(y_true, y_pred, labels=[1,0]))\n",
        "print(classification_report(y_true, y_pred, target_names=[\"non-prof\", \"prof\"]))\n",
        "print('f1-score:', f1_score(y_true, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 420   57]\n",
            " [  54 1469]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    non-prof       0.96      0.96      0.96      1523\n",
            "        prof       0.89      0.88      0.88       477\n",
            "\n",
            "    accuracy                           0.94      2000\n",
            "   macro avg       0.92      0.92      0.92      2000\n",
            "weighted avg       0.94      0.94      0.94      2000\n",
            "\n",
            "f1-score: 0.8832807570977917\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6z14DMDjvFF"
      },
      "source": [
        "#Model using Bert Uncased Classifier\n",
        "We train a model using bert uncased using the English translation of the tweets "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0u72gyhnl9Z7"
      },
      "source": [
        "#load english tweet data\n",
        "train_data = pd.read_csv('/content/drive/MyDrive/Datasets/profner/train-eng.csv')\n",
        "val_data = pd.read_csv('/content/drive/MyDrive/Datasets/profner/val-eng.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbadP7eCIH63"
      },
      "source": [
        "test_data = pd.read_csv('/content/drive/MyDrive/Datasets/profner/test-eng.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTJRao02mFks"
      },
      "source": [
        "eng_train = train_data.tweet\n",
        "eng_val = val_data.tweet\n",
        "\n",
        "labels = train_data.label\n",
        "val_labels = val_data.label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1D2mZ1gAgt0i"
      },
      "source": [
        "eng_test = test_data.tweet "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxZsbYTMmSJz"
      },
      "source": [
        "#shuffle data for both train and val sets\n",
        "idx = np.random.permutation(len(eng_train))\n",
        "x_train, y_train = eng_train[idx],labels[idx]\n",
        "\n",
        "x_val, y_val = eng_val, val_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8eCMBIbkvM9"
      },
      "source": [
        "##Preprocess tweet for Bert\n",
        "- we use a function preprocess_bert defined earlier in the code the encode our tweets, except we encode tweets to the pretrained bert-uncased model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSM0Q4qFljnK"
      },
      "source": [
        "#define var with model type\n",
        "eng_tokenizer = 'bert-base-uncased'\n",
        "max_len = 80\n",
        "#preprocess using bert\n",
        "eng_train_input, eng_train_masks = preprocess_bert(x_train, eng_tokenizer, max_len) \n",
        "eng_val_input, eng_val_masks = preprocess_bert(x_val, eng_tokenizer, max_len) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iL86AuJEg3jF"
      },
      "source": [
        "#define var with model type\n",
        "eng_tokenizer = 'bert-base-uncased'\n",
        "max_len = 80\n",
        "#preprocess using bert\n",
        "eng_test_input, eng_test_masks = preprocess_bert(eng_test, eng_tokenizer, max_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VK1urVHOoPwJ"
      },
      "source": [
        "##Fine-Tune Bert uncased classification model\n",
        "We use the create_model function defined in the mBert section. We will provide the transformer model type (bert-uncased in our case), the number of classes in our problem, and max_len of each tweet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ZMyABof8K0y"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "#making labels into numpy arrays for training in transformers and keras\n",
        "def create_eng_transformer_model(pre_trained_model, num_labels, max_len):\n",
        "  transformer_model = TFBertForSequenceClassification.from_pretrained(pre_trained_model, num_labels=num_labels)\n",
        "\n",
        "  #We create keras tensors\n",
        "  input_ids = tf.keras.layers.Input(shape=(max_len,), name='train_input', dtype=tf.int32)\n",
        "  input_masks = tf.keras.layers.Input(shape=(max_len), name='train_masks', dtype=tf.int32)\n",
        "\n",
        "  #take into account single dimension\n",
        "  seq_outputs = transformer_model(input_ids, input_masks)[0]\n",
        "  outputs = tf.keras.layers.Dense(num_labels, activation='sigmoid')(seq_outputs)\n",
        "  \n",
        "  model = tf.keras.models.Model(inputs=[input_ids,input_masks], outputs=outputs)\n",
        "\n",
        "  print(model.summary())\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEZz33bXoNTV"
      },
      "source": [
        "pt_trans_model = 'bert-base-uncased'\n",
        "num_labels = 1\n",
        "loss = 'binary_crossentropy'\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5)\n",
        "\n",
        "\n",
        "eng_model = create_eng_transformer_model(pt_trans_model, num_labels, 80)\n",
        "eng_model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iik4kmarq0_l"
      },
      "source": [
        "#make labels into numpy arrays, and prep x_val\n",
        "x_val = [eng_val_input, eng_val_masks]\n",
        "#turn labels into tensors\n",
        "y_train = np.asarray(y_train, dtype='int32')\n",
        "y_val = np.asarray(y_val, dtype='int32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFHS3uq5q7OM"
      },
      "source": [
        "#fit model to input data\n",
        "with tf.device('/device:GPU:0'):\n",
        "  eng_model.fit([eng_train_input, eng_train_masks], y_train, validation_data=(x_val, y_val), epochs=3, batch_size = 32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Chf0XT1l1JiI",
        "outputId": "45eec487-3d88-4bf9-d373-45990adf2374"
      },
      "source": [
        "eng_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "train_input (InputLayer)        [(None, 80)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "train_masks (InputLayer)        [(None, 80)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_bert_for_sequence_classifica TFSequenceClassifier 109483009   train_input[0][0]                \n",
            "                                                                 train_masks[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1)            2           tf_bert_for_sequence_classificati\n",
            "==================================================================================================\n",
            "Total params: 109,483,011\n",
            "Trainable params: 109,483,011\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDD7_ML85jEq"
      },
      "source": [
        "eng_model.save_weights('filepath/filename')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WM8P-d5dswuq"
      },
      "source": [
        "##Testing and Error Analysis on Bert Classifier\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvX3stkRuzrn"
      },
      "source": [
        "#import model if needed\n",
        "eng_model.load_weights('/content/drive/MyDrive/Colab/saved_model/engBert_profner.hdf5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFi5T7EFs2aB"
      },
      "source": [
        "#make predictions on model\n",
        "eng_y_pred = eng_model.predict(x_val)\n",
        "eng_pred = assign_class(eng_y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYYVfxB4fQze"
      },
      "source": [
        "## Confusion Maxtrix and classification report"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61-27cIztG6S",
        "outputId": "7ece16a2-c392-49da-8726-142b5512e5b9"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, f1_score, precision_score\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y_true = y_val\n",
        "y_pred = eng_pred\n",
        "\n",
        "print(confusion_matrix(y_true, eng_pred, labels=[1,0]))\n",
        "print(classification_report(y_true, eng_pred, target_names=[\"non-prof\", \"prof\"]))\n",
        "print('f1-score:', f1_score(y_true, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 418   59]\n",
            " [  53 1470]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    non-prof       0.96      0.97      0.96      1523\n",
            "        prof       0.89      0.88      0.88       477\n",
            "\n",
            "    accuracy                           0.94      2000\n",
            "   macro avg       0.92      0.92      0.92      2000\n",
            "weighted avg       0.94      0.94      0.94      2000\n",
            "\n",
            "f1-score: 0.8818565400843882\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uh-oOATfyoUR"
      },
      "source": [
        "#Concatenate transformers  and create Bilingual model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVfonSDizPyA"
      },
      "source": [
        "Step one:\n",
        "  encode Spanish text to mbert, encode English text to bert-base.\n",
        "  Encodings will be used to init a transoformer model in Spanish, and the init a transformer model in English. \n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivF5mUsY-lcJ",
        "outputId": "c4b8cc75-6823-4ae0-dad8-c8872577a7ad"
      },
      "source": [
        "!pip install transformers\n",
        "from transformers import BertTokenizer, TFBertForSequenceClassification"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.10.1 transformers-4.3.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TScabkPU-2QN"
      },
      "source": [
        "#import data in English and Spanish for training\n",
        "eng_train_data = pd.read_csv('/content/drive/MyDrive/Datasets/profner/train-eng.csv')\n",
        "es_train_data = pd.read_csv('/content/drive/MyDrive/Datasets/profner/train.csv')\n",
        "\n",
        "eng_train = eng_train_data.tweet\n",
        "es_train = es_train_data.tweet\n",
        "\n",
        "labels = eng_train_data.label\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YREbcr8h_XpM"
      },
      "source": [
        "#shuffle data for train data in english\n",
        "idx = np.random.permutation(len(eng_train))\n",
        "eng_x_train, eng_y_train = eng_train[idx],labels[idx]\n",
        "\n",
        "#shuffle train data in Spanish\n",
        "es_x_train, es_y_train = es_train[idx],labels[idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEiDKN4OzPW9"
      },
      "source": [
        "#Import data in English and in Spanish Validation\n",
        "#Import data for English and Spanish tweets\n",
        "eng_val_data = pd.read_csv('/content/drive/MyDrive/Datasets/profner/val-eng.csv')\n",
        "es_val_data = pd.read_csv('/content/drive/MyDrive/Datasets/profner/val.csv')\n",
        "\n",
        "#use dataframe to assign appropriate values to variables\n",
        "eng_val = eng_val_data.tweet\n",
        "es_val = es_val_data.tweet\n",
        "\n",
        "val_labels = eng_val_data.label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StbQ3uVjed0V"
      },
      "source": [
        "#Import data in English and in Spanish Validation\n",
        "#Import data for English and Spanish tweets\n",
        "es_test_data = pd.read_csv('/content/drive/MyDrive/Datasets/profner/test.csv')\n",
        "eng_test_data = pd.read_csv('/content/drive/MyDrive/Datasets/profner/test-eng.csv')\n",
        "\n",
        "#use dataframe to assign appropriate values to variables\n",
        "es_test = es_test_data.tweet\n",
        "eng_test = eng_test_data.tweet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Ky_VvJGyuPD"
      },
      "source": [
        "eng_tokenizer = 'bert-base-uncased'\n",
        "es_tokenizer = 'bert-base-multilingual-uncased'\n",
        "max_len = 80\n",
        "\n",
        "#train\n",
        "#eng_train_input, eng_train_masks = preprocess_bert(eng_x_train, eng_tokenizer, max_len)\n",
        "#es_train_input, es_train_masks = preprocess_bert(es_x_train, es_tokenizer, max_len)\n",
        "\n",
        "#validation\n",
        "es_val_input, es_val_masks = preprocess_bert(es_val, es_tokenizer, max_len)\n",
        "eng_val_input, eng_val_masks = preprocess_bert(eng_val, eng_tokenizer, max_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0FHPcGBjpI1"
      },
      "source": [
        "eng_tokenizer = 'bert-base-uncased'\n",
        "es_tokenizer = 'bert-base-multilingual-uncased'\n",
        "max_len = 80\n",
        "\n",
        "es_test_input, es_test_masks = preprocess_bert(es_test, es_tokenizer, max_len)\n",
        "eng_test_input, eng_test_masks = preprocess_bert(eng_test, eng_tokenizer, max_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1sttMh08sA4"
      },
      "source": [
        "#make labels into numpy arrays, and prep x_val\n",
        "x_val = [eng_val_input, eng_val_masks, es_val_input, es_val_masks]\n",
        "\n",
        "#turn labels into numpy arrays and then concatenate\n",
        "y_train = np.asarray(eng_y_train, dtype='int32')\n",
        "\n",
        "#turn labels into numpy arrays and then concatenate (the same labels in same order bc not randomized)\n",
        "y_val = np.asarray(val_labels, dtype='int32')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDXdnTvs0ayb"
      },
      "source": [
        "##Create Bilingual model\n",
        "We concatenate the output of mBERT and BERT and feed it to a dense layer to obtain predictions. Code for building model and training is below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQnge_XQ0glG"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "#making labels into numpy arrays for training in transformers and keras\n",
        "def create_concat_transformer_model(pre_trained_model_1, pre_trained_model_2, num_labels, max_len):\n",
        "  eng_transformer_model = TFBertForSequenceClassification.from_pretrained(pre_trained_model_1, num_labels=num_labels)\n",
        "  es_transformer_model = TFBertForSequenceClassification.from_pretrained(pre_trained_model_2, num_labels=num_labels)\n",
        "  \n",
        "  #We create keras tensors english\n",
        "  eng_input_ids = tf.keras.layers.Input(shape=(max_len,), name='eng_train_input', dtype=tf.int32)\n",
        "  eng_input_masks = tf.keras.layers.Input(shape=(max_len), name='eng_train_masks', dtype=tf.int32)\n",
        "\n",
        "  #We create keras tensors Spanish\n",
        "  es_input_ids = tf.keras.layers.Input(shape=(max_len,), name='es_train_input', dtype=tf.int32)\n",
        "  es_input_masks = tf.keras.layers.Input(shape=(max_len), name='es_train_masks', dtype=tf.int32)\n",
        "  \n",
        "  #take into account single dimension\n",
        "  eng_seq_outputs = eng_transformer_model(eng_input_ids, eng_input_masks)[0]\n",
        "  es_seq_outputs = es_transformer_model(es_input_ids, es_input_masks)[0]\n",
        "\n",
        "  #concatenate outputs sequences from transformer models\n",
        "  concat_outputs = tf.concat([eng_seq_outputs, es_seq_outputs],1)\n",
        "  outputs = tf.keras.layers.Dense(num_labels, activation='sigmoid')(concat_outputs)\n",
        "  \n",
        "  model = tf.keras.models.Model(inputs=[eng_input_ids,eng_input_masks, es_input_ids, es_input_masks], outputs=outputs)\n",
        "\n",
        "  print(model.summary())\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ofbDXmmD6xqF",
        "outputId": "3ea0c728-7d90-4ac0-8f9e-bc63087d1de0"
      },
      "source": [
        "#call create model function and compile\n",
        "eng_trans_model = 'bert-base-uncased'\n",
        "es_trans_model = 'bert-base-multilingual-uncased'\n",
        "num_labels = 1\n",
        "loss = 'binary_crossentropy'\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5)\n",
        "\n",
        "\n",
        "concat_model = create_concat_transformer_model(eng_trans_model, es_trans_model, num_labels, 80)\n",
        "concat_model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7f02aa6dac20> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function wrap at 0x7f02aa6dac20> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convertWARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "eng_train_input (InputLayer)    [(None, 80)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "eng_train_masks (InputLayer)    [(None, 80)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "es_train_input (InputLayer)     [(None, 80)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "es_train_masks (InputLayer)     [(None, 80)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_bert_for_sequence_classifica TFSequenceClassifier 109483009   eng_train_input[0][0]            \n",
            "                                                                 eng_train_masks[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "tf_bert_for_sequence_classifica TFSequenceClassifier 167357185   es_train_input[0][0]             \n",
            "                                                                 es_train_masks[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.concat (TFOpLambda)          (None, 2)            0           tf_bert_for_sequence_classificati\n",
            "                                                                 tf_bert_for_sequence_classificati\n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 1)            3           tf.concat[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 276,840,197\n",
            "Trainable params: 276,840,197\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbq9_VDn64ct",
        "outputId": "b4349ad6-c789-4572-bf0b-574370acfc1b"
      },
      "source": [
        "#fit model to input data\n",
        "\n",
        "with tf.device('/device:GPU:0'):\n",
        "  concat_model.fit([eng_train_input, eng_train_masks, es_train_input, es_train_masks], y_train, validation_data=(x_val, y_val), epochs=4, batch_size = 32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.4256 - accuracy: 0.8259WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "188/188 [==============================] - 155s 717ms/step - loss: 0.4250 - accuracy: 0.8262 - val_loss: 0.1693 - val_accuracy: 0.9450\n",
            "Epoch 2/4\n",
            "188/188 [==============================] - 133s 706ms/step - loss: 0.1299 - accuracy: 0.9578 - val_loss: 0.1554 - val_accuracy: 0.9520\n",
            "Epoch 3/4\n",
            "188/188 [==============================] - 133s 706ms/step - loss: 0.0602 - accuracy: 0.9823 - val_loss: 0.1733 - val_accuracy: 0.9410\n",
            "Epoch 4/4\n",
            "188/188 [==============================] - 133s 706ms/step - loss: 0.0339 - accuracy: 0.9900 - val_loss: 0.1734 - val_accuracy: 0.9545\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onniG3m07hsY"
      },
      "source": [
        "#save model\n",
        "concat_model.save_weights('filepath')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_qVXzqd8LFZ"
      },
      "source": [
        "##Predict and Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YR7ozMkai6B"
      },
      "source": [
        "concat_model.load_weights('/content/drive/MyDrive/Colab/saved_model/concat_model_weight_1.hdf5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbKl6Dot8hZ5"
      },
      "source": [
        "x_test = [eng_val_input, eng_val_masks, es_val_input, es_val_masks]\n",
        "pred = concat_model.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJhSnUva8UXN",
        "outputId": "8619a2d6-3aca-44a7-daf5-94672348b1b6"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "y_true = y_val\n",
        "y_pred = assign_class(pred)\n",
        "\n",
        "print(confusion_matrix(y_true, y_pred, labels=[1,0]))\n",
        "print(classification_report(y_true, y_pred, target_names=[\"non-prof\", \"prof\"]))\n",
        "print('f1-score:', f1_score(y_true, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 419   58]\n",
            " [  38 1485]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    non-prof       0.96      0.98      0.97      1523\n",
            "        prof       0.92      0.88      0.90       477\n",
            "\n",
            "    accuracy                           0.95      2000\n",
            "   macro avg       0.94      0.93      0.93      2000\n",
            "weighted avg       0.95      0.95      0.95      2000\n",
            "\n",
            "f1-score: 0.8972162740899358\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTkfpsAqmHFX",
        "outputId": "710ce668-aa56-4539-ceef-94c2f71e9b34"
      },
      "source": [
        "print(len(y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "27000\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
